---
title: "2 â€” Count words"
date: "2024-01-02"
date-modified: last-modified
image: "two.jpg"
format:
  html:
    toc: true
    warning: false
    message: false
    fig-width: 3
tbl-colwidths: [25,75]
categories: [count, words, terms, tokens]
filters:
  - line-highlight
---


## Load the kids TV data

Read in a table of kids TV shows on Netflix.
```{r}
#| cache: true

library(tidyverse)

tv_shows <- read_csv('https://tidy-mn.github.io/qualitative-guide/posts/data/kids_netflix_shows.csv')
```


## Count totals in each group or category
```{r}
library(tidyverse)

type_count <- tv_shows %>%
              count(type) # type can be any column in the data

type_count
```


## Count totals by release year for each type
```{r}
year_type_count <- tv_shows %>%
                   count(release_year, type) # Can add multiple column names

year_type_count %>% head()
```


## Count totals in wide format table
```{r}
library(janitor)

tv_tabyl <- tv_shows %>%
            tabyl(release_year, type) %>%
            adorn_totals("col") %>%
            adorn_totals("row") %>%
            filter(release_year > 2016)

tv_tabyl  
```


## Rank occurence of words

> `tokens` = words or phrases

Top **10** words in the genre column.

```{r}
library(tidytext)

genre_count <- tv_shows %>%
               unnest_tokens(word, genre) %>%
               count(word, sort = TRUE)

genre_count %>% head(10)
```


## Additional token options

::: {.panel-tabset}

### Count 2-word phrases

Rather than counting every single word, we may be interested in counting how often words occur together. To do this we use `unnest_ngrams()` and set the *n* argument to `2`. If an `<NA>` appears in the count column, it indicates a show that had fewer than two words in the genre column.

```{r}
#| source-line-numbers: "2"
genre_count <- tv_shows %>%
               unnest_ngrams(word, genre, n = 2) %>%
               count(word, sort = TRUE) 

genre_count %>% head(10)
```

> The words *children* and *family* were the most often to occur together.


### Split phrases separated by a comma

In this data set multiple genres are separated by a comma, so we can treat each phrase before and after a comma as a single genre or token. To do this we use `unnest_regex()` and set the *pattern* argument to `", "`. This will split the text wherever the sequence of a comma followed by a space occurs. Now the genres will be counted as they were intended in the data.

```{r}
#| source-line-numbers: "2"
genre_count <- tv_shows %>%
               unnest_regex(word, genre, pattern = ", ") %>%
               count(word, sort = TRUE) 

genre_count %>% head(10)
```

:::

## Stop words

> `stop words` = Common words or phrases such as `the`, `of`, and `to`.

When comparing survey responses and narratives, some of the most common words are often the articles, such as `the`, `a`, and `an`, that don't offer much in terms of signaling the intent or theme of the text. These filler words are commonly referred to as *stop words*. 

A list of stop words is included in the `tidytext` package. Let's load the words and store them in a variable called `exclude`. Here's the first few for example, but go ahead and take a look at the full list to get a better understanding of what may be considered a stop word.

```{r}
exclude <- stop_words$word

exclude %>% head()
```


## Excluding unwanted words

For this example we will focus on the `description` column. This column contains some free text describing the content of the show. 

First, let's start by counting the occurrence of all words in the descriptions.

```{r}
word_count <- tv_shows %>%
              unnest_tokens(word, description) %>%
              count(word, sort = TRUE) 

word_count %>% head(15)
```


> Just as we expected. Lot's of stop words. 

<br>

Let's exclude the stop words from the list with the `filter()` function. This should give us a much more informative list of words.

```{r}
#| source-line-numbers: "3"
word_count <- tv_shows %>%
              unnest_tokens(word, description) %>%
              filter(!word %in% exclude) %>%
              count(word, sort = TRUE) 

word_count %>% head(15)
```

## Additional stop word options

::: {.panel-tabset}

### Exclude more words

For a given data set there may be additional stop words that provide little insight into the text. For example, the words "tv" and "series" are not very informative if each row in your data is about a TV show.

```{r}
#| source-line-numbers: "1-4"
exclude <- c(stop_words$word,
             "tv",
             "series",
             "movie",
             "documentary")

word_count <- tv_shows %>%
              unnest_tokens(word, description) %>%
              filter(!word %in% exclude) %>%
              count(word, sort = TRUE) 

word_count %>% head(15)
```


### Keep some words

Similarly, a word that is included in the stop word list may be informative for a particular data set. When this is the case, we want to keep the word by removing it from the exclusion list. For example, we may want to know the number of show descriptions that reference `one`, `two` or `three` characters or objects.

Here's how we can keep the words "one", "two" and "three".

```{r}
#| source-line-numbers: "3-5"
exclude <- stop_words$word

keep <- c("one", "two", "three")

exclude <- exclude[!exclude %in% keep]

word_count <- tv_shows %>%
              unnest_tokens(word, description) %>%
              filter(!word %in% exclude) %>%
              count(word, sort = TRUE) 

word_count %>% head(15)
```

> It appears `"two"` is the most common number to be referenced.

:::

