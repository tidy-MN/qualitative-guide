{"title":"2 — Count words","markdown":{"yaml":{"title":"2 — Count words","date":"2024-01-02","date-modified":"last-modified","image":"two.jpg","format":{"html":{"toc":true,"warning":false,"message":false,"fig-width":3}},"tbl-colwidths":[25,75],"categories":["count","words","terms","tokens"],"filters":["line-highlight"]},"headingText":"Load the data","containsRefs":false,"markdown":"\n\n\n```{r}\n#| cache: true\n\nlibrary(tidyverse)\n\ntv_ratings <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv') %>%\n              rename(genre = listed_in)\n```\n\n\n## Count totals in each group or category\n```{r}\nlibrary(tidyverse)\n\ntype_count <- tv_ratings %>%\n              count(type) # type can be any column in the data\n\ntype_count\n```\n\n\n## Count totals by release year for each type\n```{r}\nyear_type_count <- tv_ratings %>%\n                   count(release_year, type) # Add multiple column names\n\nyear_type_count %>% head()\n```\n\n\n## Count totals in wide format table\n```{r}\nlibrary(janitor)\n\ntv_tabyl <- tv_ratings %>%\n            tabyl(release_year, type) %>%\n            adorn_totals() \n\ntv_tabyl %>% head() \n```\n\n\n## Rank occurence of words\n\n> `tokens` = words or phrases\n\nTop **10** words in the genre column.\n\n```{r}\nlibrary(tidytext)\n\ngenre_count <- tv_ratings %>%\n               unnest_tokens(word, genre) %>%\n               count(word, sort = TRUE)\n\ngenre_count %>% head(10)\n```\n\n\n## Additional token options\n\n::: {.panel-tabset}\n\n### Count 2-word phrases\n\nRather than counting every single word, we may be interested in counting how often words occur together. To do this we use `unnest_ngrams()` and set the *n* argument to `2`. The `<NA>` result is the count of shows that had fewer than two words in the genre column, such as `Documentaries`.\n\n```{r}\n#| source-line-numbers: \"2\"\ngenre_count <- tv_ratings %>%\n               unnest_ngrams(word, genre, n = 2) %>%\n               count(word, sort = TRUE) \n\ngenre_count %>% head(10)\n```\n\n### Split phrases separated by a comma\n\nIn this data set multiple genres are separated by a comma, so we can treat each phrase before and after a comma as a single genre or token. To do this we use `unnest_regex()` and set the *pattern* argument to `\", \"`. This will split the text wherever the sequence of a comma followed by a space occurs. Now the genres will be counted as they were intended in the data.\n\n```{r}\n#| source-line-numbers: \"2\"\ngenre_count <- tv_ratings %>%\n               unnest_regex(word, genre, pattern = \", \") %>%\n               count(word, sort = TRUE) \n\ngenre_count %>% head(10)\n```\n\n:::\n\n## Stop words\n\n> `stop words` = Common words or phrases such as `the`, `of`, and `to`.\n\nWhen comparing survey responses and narratives, some of the most common words are often the articles, such as `the`, `a`, and `an`, that don't offer much in terms of signaling the intent or theme of the text. These filler words are commonly referred to as *stop words*. \n\nA list of stop words is included in the `tidytext` package. Let's load the words and store them in a variable called `exclude`. Here's the first few for example, but go ahead and take a look at the full list to get a better understanding of what may be considered a stop word.\n\n```{r}\nexclude <- stop_words$word\n\nexclude %>% head()\n```\n\n\n## Excluding unwanted words\n\nFor this example we will focus on the `description` column. This column contains some free text describing the content of the show. \n\nFirst, let's start by counting the occurrence of all words in the descriptions.\n\n```{r}\nword_count <- tv_ratings %>%\n              unnest_tokens(word, description) %>%\n              count(word, sort = TRUE) \n\nword_count %>% head(15)\n```\n\n<br>\n\nJust as we expected. Lot's of stop words. \n\nLet's exclude the stop words from the list with the `filter()` function. This should give us a much more informative list of words.\n\n```{r}\n#| source-line-numbers: \"3\"\nword_count <- tv_ratings %>%\n              unnest_tokens(word, description) %>%\n              filter(!word %in% exclude) %>%\n              count(word, sort = TRUE) \n\nword_count %>% head(15)\n```\n\n## Additional stop word options\n\n::: {.panel-tabset}\n\n### Exclude more words\n\nFor a given data set there may be additional stop words that provide little insight into the text. For example, the words \"tv\" and \"series\" are not very informative if each row in your data is about a TV show.\n\n```{r}\n#| source-line-numbers: \"1-4\"\nexclude <- c(stop_words$word,\n             \"tv\",\n             \"series\",\n             \"movie\",\n             \"documentary\")\n\nword_count <- tv_ratings %>%\n              unnest_tokens(word, description) %>%\n              filter(!word %in% exclude) %>%\n              count(word, sort = TRUE) \n\nword_count %>% head(15)\n```\n\n\n### Keep some words\n\nSimilarly, a word that is included in the stop word list may be informative for a particular data set. When this is the case, we want to keep the word by removing it from the exclusion list. For example, we may want to know the number of show descriptions that reference `one`, `two` or `three` characters or objects.\n\nHere's how we can keep the words \"one\", \"two\" and \"three\".\n\n```{r}\n#| source-line-numbers: \"3-5\"\nexclude <- stop_words$word\n\nkeep <- c(\"one\", \"two\", \"three\")\n\nexclude <- exclude[!exclude %in% keep]\n\nword_count <- tv_ratings %>%\n              unnest_tokens(word, description) %>%\n              filter(!word %in% exclude) %>%\n              count(word, sort = TRUE) \n\nword_count %>% head(15)\n```\n\n:::\n\n","srcMarkdownNoYaml":"\n\n\n## Load the data\n```{r}\n#| cache: true\n\nlibrary(tidyverse)\n\ntv_ratings <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv') %>%\n              rename(genre = listed_in)\n```\n\n\n## Count totals in each group or category\n```{r}\nlibrary(tidyverse)\n\ntype_count <- tv_ratings %>%\n              count(type) # type can be any column in the data\n\ntype_count\n```\n\n\n## Count totals by release year for each type\n```{r}\nyear_type_count <- tv_ratings %>%\n                   count(release_year, type) # Add multiple column names\n\nyear_type_count %>% head()\n```\n\n\n## Count totals in wide format table\n```{r}\nlibrary(janitor)\n\ntv_tabyl <- tv_ratings %>%\n            tabyl(release_year, type) %>%\n            adorn_totals() \n\ntv_tabyl %>% head() \n```\n\n\n## Rank occurence of words\n\n> `tokens` = words or phrases\n\nTop **10** words in the genre column.\n\n```{r}\nlibrary(tidytext)\n\ngenre_count <- tv_ratings %>%\n               unnest_tokens(word, genre) %>%\n               count(word, sort = TRUE)\n\ngenre_count %>% head(10)\n```\n\n\n## Additional token options\n\n::: {.panel-tabset}\n\n### Count 2-word phrases\n\nRather than counting every single word, we may be interested in counting how often words occur together. To do this we use `unnest_ngrams()` and set the *n* argument to `2`. The `<NA>` result is the count of shows that had fewer than two words in the genre column, such as `Documentaries`.\n\n```{r}\n#| source-line-numbers: \"2\"\ngenre_count <- tv_ratings %>%\n               unnest_ngrams(word, genre, n = 2) %>%\n               count(word, sort = TRUE) \n\ngenre_count %>% head(10)\n```\n\n### Split phrases separated by a comma\n\nIn this data set multiple genres are separated by a comma, so we can treat each phrase before and after a comma as a single genre or token. To do this we use `unnest_regex()` and set the *pattern* argument to `\", \"`. This will split the text wherever the sequence of a comma followed by a space occurs. Now the genres will be counted as they were intended in the data.\n\n```{r}\n#| source-line-numbers: \"2\"\ngenre_count <- tv_ratings %>%\n               unnest_regex(word, genre, pattern = \", \") %>%\n               count(word, sort = TRUE) \n\ngenre_count %>% head(10)\n```\n\n:::\n\n## Stop words\n\n> `stop words` = Common words or phrases such as `the`, `of`, and `to`.\n\nWhen comparing survey responses and narratives, some of the most common words are often the articles, such as `the`, `a`, and `an`, that don't offer much in terms of signaling the intent or theme of the text. These filler words are commonly referred to as *stop words*. \n\nA list of stop words is included in the `tidytext` package. Let's load the words and store them in a variable called `exclude`. Here's the first few for example, but go ahead and take a look at the full list to get a better understanding of what may be considered a stop word.\n\n```{r}\nexclude <- stop_words$word\n\nexclude %>% head()\n```\n\n\n## Excluding unwanted words\n\nFor this example we will focus on the `description` column. This column contains some free text describing the content of the show. \n\nFirst, let's start by counting the occurrence of all words in the descriptions.\n\n```{r}\nword_count <- tv_ratings %>%\n              unnest_tokens(word, description) %>%\n              count(word, sort = TRUE) \n\nword_count %>% head(15)\n```\n\n<br>\n\nJust as we expected. Lot's of stop words. \n\nLet's exclude the stop words from the list with the `filter()` function. This should give us a much more informative list of words.\n\n```{r}\n#| source-line-numbers: \"3\"\nword_count <- tv_ratings %>%\n              unnest_tokens(word, description) %>%\n              filter(!word %in% exclude) %>%\n              count(word, sort = TRUE) \n\nword_count %>% head(15)\n```\n\n## Additional stop word options\n\n::: {.panel-tabset}\n\n### Exclude more words\n\nFor a given data set there may be additional stop words that provide little insight into the text. For example, the words \"tv\" and \"series\" are not very informative if each row in your data is about a TV show.\n\n```{r}\n#| source-line-numbers: \"1-4\"\nexclude <- c(stop_words$word,\n             \"tv\",\n             \"series\",\n             \"movie\",\n             \"documentary\")\n\nword_count <- tv_ratings %>%\n              unnest_tokens(word, description) %>%\n              filter(!word %in% exclude) %>%\n              count(word, sort = TRUE) \n\nword_count %>% head(15)\n```\n\n\n### Keep some words\n\nSimilarly, a word that is included in the stop word list may be informative for a particular data set. When this is the case, we want to keep the word by removing it from the exclusion list. For example, we may want to know the number of show descriptions that reference `one`, `two` or `three` characters or objects.\n\nHere's how we can keep the words \"one\", \"two\" and \"three\".\n\n```{r}\n#| source-line-numbers: \"3-5\"\nexclude <- stop_words$word\n\nkeep <- c(\"one\", \"two\", \"three\")\n\nexclude <- exclude[!exclude %in% keep]\n\nword_count <- tv_ratings %>%\n              unnest_tokens(word, description) %>%\n              filter(!word %in% exclude) %>%\n              count(word, sort = TRUE) \n\nword_count %>% head(15)\n```\n\n:::\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":3,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":[25,75],"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"filters":["line-highlight"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","theme":"minty","title-block-banner":false,"title":"2 — Count words","date":"2024-01-02","date-modified":"last-modified","image":"two.jpg","categories":["count","words","terms","tokens"],"message":false},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}