{
  "hash": "a1f349e244f1e3d14f1601d3becec909",
  "result": {
    "markdown": "---\ntitle: \"2 — Count words\"\ndate: \"2024-01-02\"\ndate-modified: last-modified\nimage: \"two.jpg\"\nformat:\n  html:\n    toc: true\n    warning: false\n    message: false\n    fig-width: 3\ntbl-colwidths: [25,75]\ncategories: [count, words, terms, tokens]\nfilters:\n  - line-highlight\n---\n\n\n\n## Load the kids TV data\n\nRead in a table of kids TV shows on Netflix.\n\n::: {.cell hash='index_cache/html/unnamed-chunk-1_6c8e3e729fee53de04cef9cf5a1eb90d'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\ntv_shows <- read_csv('https://tidy-mn.github.io/qualitative-guide/posts/data/kids_netflix_shows.csv')\n```\n:::\n\n\n\n## Count totals in each group or category\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\ntype_count <- tv_shows %>%\n              count(type) # type can be any column in the data\n\ntype_count\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  type        n\n  <chr>   <int>\n1 Movie     532\n2 TV Show   414\n```\n:::\n:::\n\n\n\n## Count totals by release year for each type\n\n::: {.cell}\n\n```{.r .cell-code}\nyear_type_count <- tv_shows %>%\n                   count(release_year, type) # Can add multiple column names\n\nyear_type_count %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3\n  release_year type      n\n         <dbl> <chr> <int>\n1         1954 Movie     1\n2         1968 Movie     1\n3         1971 Movie     1\n4         1973 Movie     1\n5         1977 Movie     1\n6         1978 Movie     1\n```\n:::\n:::\n\n\n\n## Count totals in wide format table\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(janitor)\n\ntv_tabyl <- tv_shows %>%\n            tabyl(release_year, type) %>%\n            adorn_totals(\"col\") %>%\n            adorn_totals(\"row\") %>%\n            filter(release_year > 2016)\n\ntv_tabyl  \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n release_year Movie TV Show Total\n         2017    48      52   100\n         2018    63      65   128\n         2019    72      56   128\n         2020    79      73   152\n         2021     1       4     5\n        Total   532     414   946\n```\n:::\n:::\n\n\n\n## Rank occurence of words\n\n> `tokens` = words or phrases\n\nTop **10** words in the genre column.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidytext)\n\ngenre_count <- tv_shows %>%\n               unnest_tokens(word, genre) %>%\n               count(word, sort = TRUE)\n\ngenre_count %>% head(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 2\n   word          n\n   <chr>     <int>\n 1 tv          650\n 2 movies      602\n 3 children    532\n 4 family      532\n 5 kids        414\n 6 comedies    342\n 7 dramas       86\n 8 shows        61\n 9 action       43\n10 adventure    43\n```\n:::\n:::\n\n\n\n## Additional token options\n\n::: {.panel-tabset}\n\n### Count 2-word phrases\n\nRather than counting every single word, we may be interested in counting how often words occur together. To do this we use `unnest_ngrams()` and set the *n* argument to `2`. If an `<NA>` appears in the count column, it indicates a show that had fewer than two words in the genre column.\n\n\n::: {.cell source-line-numbers='2'}\n\n```{.r .cell-code}\ngenre_count <- tv_shows %>%\n               unnest_ngrams(word, genre, n = 2) %>%\n               count(word, sort = TRUE) \n\ngenre_count %>% head(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 2\n   word                 n\n   <chr>            <int>\n 1 children family    532\n 2 family movies      532\n 3 kids tv            414\n 4 movies comedies    225\n 5 tv tv              140\n 6 tv comedies        117\n 7 movies dramas       64\n 8 tv shows            61\n 9 action adventure    43\n10 fi fantasy          32\n```\n:::\n:::\n\n\n> The words *children* and *family* were the most often to occur together.\n\n\n### Split phrases separated by a comma\n\nIn this data set multiple genres are separated by a comma, so we can treat each phrase before and after a comma as a single genre or token. To do this we use `unnest_regex()` and set the *pattern* argument to `\", \"`. This will split the text wherever the sequence of a comma followed by a space occurs. Now the genres will be counted as they were intended in the data.\n\n\n::: {.cell source-line-numbers='2'}\n\n```{.r .cell-code}\ngenre_count <- tv_shows %>%\n               unnest_regex(word, genre, pattern = \", \") %>%\n               count(word, sort = TRUE) \n\ngenre_count %>% head(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 2\n   word                         n\n   <chr>                    <int>\n 1 children & family movies   532\n 2 kids' tv                   414\n 3 comedies                   225\n 4 tv comedies                117\n 5 dramas                      75\n 6 british tv shows            27\n 7 music & musicals            27\n 8 korean tv shows             23\n 9 tv action & adventure       22\n10 action & adventure          21\n```\n:::\n:::\n\n\n:::\n\n## Stop words\n\n> `stop words` = Common words or phrases such as `the`, `of`, and `to`.\n\nWhen comparing survey responses and narratives, some of the most common words are often the articles, such as `the`, `a`, and `an`, that don't offer much in terms of signaling the intent or theme of the text. These filler words are commonly referred to as *stop words*. \n\nA list of stop words is included in the `tidytext` package. Let's load the words and store them in a variable called `exclude`. Here's the first few for example, but go ahead and take a look at the full list to get a better understanding of what may be considered a stop word.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexclude <- stop_words$word\n\nexclude %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"a\"         \"a's\"       \"able\"      \"about\"     \"above\"     \"according\"\n```\n:::\n:::\n\n\n\n## Excluding unwanted words\n\nFor this example we will focus on the `description` column. This column contains some free text describing the content of the show. \n\nFirst, let's start by counting the occurrence of all words in the descriptions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nword_count <- tv_shows %>%\n              unnest_tokens(word, description) %>%\n              count(word, sort = TRUE) \n\nword_count %>% head(15)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15 × 2\n   word      n\n   <chr> <int>\n 1 the    1048\n 2 a      1020\n 3 and     850\n 4 to      804\n 5 of      509\n 6 in      377\n 7 his     343\n 8 with    272\n 9 her     233\n10 their   224\n11 when    207\n12 on      198\n13 an      184\n14 for     179\n15 from    168\n```\n:::\n:::\n\n\n\n> Just as we expected. Lot's of stop words. \n\n<br>\n\nLet's exclude the stop words from the list with the `filter()` function. This should give us a much more informative list of words.\n\n\n::: {.cell source-line-numbers='3'}\n\n```{.r .cell-code}\nword_count <- tv_shows %>%\n              unnest_tokens(word, description) %>%\n              filter(!word %in% exclude) %>%\n              count(word, sort = TRUE) \n\nword_count %>% head(15)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15 × 2\n   word           n\n   <chr>      <int>\n 1 friends      136\n 2 world         92\n 3 save          78\n 4 family        64\n 5 life          64\n 6 series        62\n 7 adventures    60\n 8 evil          60\n 9 fun           56\n10 adventure     55\n11 home          51\n12 school        51\n13 team          43\n14 christmas     42\n15 city          40\n```\n:::\n:::\n\n\n## Additional stop word options\n\n::: {.panel-tabset}\n\n### Exclude more words\n\nFor a given data set there may be additional stop words that provide little insight into the text. For example, the words \"tv\" and \"series\" are not very informative if each row in your data is about a TV show.\n\n\n::: {.cell source-line-numbers='1-4'}\n\n```{.r .cell-code}\nexclude <- c(stop_words$word,\n             \"tv\",\n             \"series\",\n             \"movie\",\n             \"documentary\")\n\nword_count <- tv_shows %>%\n              unnest_tokens(word, description) %>%\n              filter(!word %in% exclude) %>%\n              count(word, sort = TRUE) \n\nword_count %>% head(15)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15 × 2\n   word           n\n   <chr>      <int>\n 1 friends      136\n 2 world         92\n 3 save          78\n 4 family        64\n 5 life          64\n 6 adventures    60\n 7 evil          60\n 8 fun           56\n 9 adventure     55\n10 home          51\n11 school        51\n12 team          43\n13 christmas     42\n14 city          40\n15 animated      39\n```\n:::\n:::\n\n\n\n### Keep some words\n\nSimilarly, a word that is included in the stop word list may be informative for a particular data set. When this is the case, we want to keep the word by removing it from the exclusion list. For example, we may want to know the number of show descriptions that reference `one`, `two` or `three` characters or objects.\n\nHere's how we can keep the words \"one\", \"two\" and \"three\".\n\n\n::: {.cell source-line-numbers='3-5'}\n\n```{.r .cell-code}\nexclude <- stop_words$word\n\nkeep <- c(\"one\", \"two\", \"three\")\n\nexclude <- exclude[!exclude %in% keep]\n\nword_count <- tv_shows %>%\n              unnest_tokens(word, description) %>%\n              filter(!word %in% exclude) %>%\n              count(word, sort = TRUE) \n\nword_count %>% head(15)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15 × 2\n   word           n\n   <chr>      <int>\n 1 friends      136\n 2 world         92\n 3 save          78\n 4 family        64\n 5 life          64\n 6 series        62\n 7 adventures    60\n 8 evil          60\n 9 fun           56\n10 adventure     55\n11 home          51\n12 school        51\n13 two           44\n14 team          43\n15 christmas     42\n```\n:::\n:::\n\n\n> It appears `\"two\"` is the most common number to be referenced.\n\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}