{
  "hash": "a448a4db660095b9d557be6f3746988e",
  "result": {
    "markdown": "---\ntitle: \"2 — Count words\"\ndate: \"2024-01-02\"\ndate-modified: last-modified\nimage: \"two.jpg\"\nformat:\n  html:\n    toc: true\n    warning: false\n    message: false\n    fig-width: 3\ntbl-colwidths: [25,75]\ncategories: [count, words, terms, tokens]\nfilters:\n  - line-highlight\n---\n\n\n\n## Load the data\n\n::: {.cell hash='index_cache/html/unnamed-chunk-1_da516150d56b35a2eea0fe93057bd957'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\ntv_ratings <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv') %>%\n              rename(genre = listed_in)\n```\n:::\n\n\n\n## Count totals in each group or category\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\ntype_count <- tv_ratings %>%\n              count(type) # type can be any column in the data\n\ntype_count\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  type        n\n  <chr>   <int>\n1 Movie    5377\n2 TV Show  2410\n```\n:::\n:::\n\n\n\n## Count totals by release year for each type\n\n::: {.cell}\n\n```{.r .cell-code}\nyear_type_count <- tv_ratings %>%\n                   count(release_year, type) # Add multiple column names\n\nyear_type_count %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3\n  release_year type        n\n         <dbl> <chr>   <int>\n1         1925 TV Show     1\n2         1942 Movie       2\n3         1943 Movie       3\n4         1944 Movie       3\n5         1945 Movie       3\n6         1946 Movie       1\n```\n:::\n:::\n\n\n\n## Count totals in wide format table\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(janitor)\n\ntv_tabyl <- tv_ratings %>%\n            tabyl(release_year, type) %>%\n            adorn_totals() \n\ntv_tabyl %>% head() \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n release_year Movie TV Show\n         1925     0       1\n         1942     2       0\n         1943     3       0\n         1944     3       0\n         1945     3       0\n         1946     1       1\n```\n:::\n:::\n\n\n\n## Rank occurence of words\n\n> `tokens` = words or phrases\n\nTop **10** words in the genre column.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidytext)\n\ngenre_count <- tv_ratings %>%\n               unnest_tokens(word, genre) %>%\n               count(word, sort = TRUE)\n\ngenre_count %>% head(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 2\n   word              n\n   <chr>         <int>\n 1 movies         4989\n 2 tv             4972\n 3 international  3636\n 4 dramas         2810\n 5 shows          2612\n 6 comedies       1996\n 7 action          871\n 8 adventure       871\n 9 romantic        864\n10 documentaries   786\n```\n:::\n:::\n\n\n\n## Additional token options\n\n::: {.panel-tabset}\n\n### Count 2-word phrases\n\nRather than counting every single word, we may be interested in counting how often words occur together. To do this we use `unnest_ngrams()` and set the *n* argument to `2`. The `<NA>` result is the count of shows that had fewer than two words in the genre column, such as `Documentaries`.\n\n\n::: {.cell source-line-numbers='2'}\n\n```{.r .cell-code}\ngenre_count <- tv_ratings %>%\n               unnest_ngrams(word, genre, n = 2) %>%\n               count(word, sort = TRUE) \n\ngenre_count %>% head(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 2\n   word                     n\n   <chr>                <int>\n 1 tv shows              2560\n 2 international movies  2437\n 3 international tv      1199\n 4 dramas international  1071\n 5 action adventure       871\n 6 shows tv               862\n 7 <NA>                   727\n 8 tv dramas              704\n 9 independent movies     673\n10 children family        532\n```\n:::\n:::\n\n\n### Split phrases separated by a comma\n\nIn this data set multiple genres are separated by a comma, so we can treat each phrase before and after a comma as a single genre or token. To do this we use `unnest_regex()` and set the *pattern* argument to `\", \"`. This will split the text wherever the sequence of a comma followed by a space occurs. Now the genres will be counted as they were intended in the data.\n\n\n::: {.cell source-line-numbers='2'}\n\n```{.r .cell-code}\ngenre_count <- tv_ratings %>%\n               unnest_regex(word, genre, pattern = \", \") %>%\n               count(word, sort = TRUE) \n\ngenre_count %>% head(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 2\n   word                         n\n   <chr>                    <int>\n 1 international movies      2437\n 2 dramas                    2106\n 3 comedies                  1471\n 4 international tv shows    1199\n 5 documentaries              786\n 6 action & adventure         721\n 7 tv dramas                  704\n 8 independent movies         673\n 9 children & family movies   532\n10 romantic movies            531\n```\n:::\n:::\n\n\n:::\n\n## Stop words\n\n> `stop words` = Common words or phrases such as `the`, `of`, and `to`.\n\nWhen comparing survey responses and narratives, some of the most common words are often the articles, such as `the`, `a`, and `an`, that don't offer much in terms of signaling the intent or theme of the text. These filler words are commonly referred to as *stop words*. \n\nA list of stop words is included in the `tidytext` package. Let's load the words and store them in a variable called `exclude`. Here's the first few for example, but go ahead and take a look at the full list to get a better understanding of what may be considered a stop word.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexclude <- stop_words$word\n\nexclude %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"a\"         \"a's\"       \"able\"      \"about\"     \"above\"     \"according\"\n```\n:::\n:::\n\n\n\n## Excluding unwanted words\n\nFor this example we will focus on the `description` column. This column contains some free text describing the content of the show. \n\nFirst, let's start by counting the occurrence of all words in the descriptions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nword_count <- tv_ratings %>%\n              unnest_tokens(word, description) %>%\n              count(word, sort = TRUE) \n\nword_count %>% head(15)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15 × 2\n   word      n\n   <chr> <int>\n 1 a     10152\n 2 the    7226\n 3 to     5701\n 4 and    5629\n 5 of     4731\n 6 in     3920\n 7 his    3020\n 8 with   1976\n 9 her    1884\n10 an     1728\n11 for    1579\n12 on     1558\n13 their  1472\n14 when   1325\n15 this   1246\n```\n:::\n:::\n\n\n<br>\n\nJust as we expected. Lot's of stop words. \n\nLet's exclude the stop words from the list with the `filter()` function. This should give us a much more informative list of words.\n\n\n::: {.cell source-line-numbers='3'}\n\n```{.r .cell-code}\nword_count <- tv_ratings %>%\n              unnest_tokens(word, description) %>%\n              filter(!word %in% exclude) %>%\n              count(word, sort = TRUE) \n\nword_count %>% head(15)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15 × 2\n   word            n\n   <chr>       <int>\n 1 life          746\n 2 family        497\n 3 world         453\n 4 love          447\n 5 woman         402\n 6 friends       383\n 7 series        358\n 8 documentary   326\n 9 school        290\n10 home          263\n11 lives         251\n12 takes         233\n13 father        228\n14 girl          209\n15 special       190\n```\n:::\n:::\n\n\n## Additional stop word options\n\n::: {.panel-tabset}\n\n### Exclude more words\n\nFor a given data set there may be additional stop words that provide little insight into the text. For example, the words \"tv\" and \"series\" are not very informative if each row in your data is about a TV show.\n\n\n::: {.cell source-line-numbers='1-4'}\n\n```{.r .cell-code}\nexclude <- c(stop_words$word,\n             \"tv\",\n             \"series\",\n             \"movie\",\n             \"documentary\")\n\nword_count <- tv_ratings %>%\n              unnest_tokens(word, description) %>%\n              filter(!word %in% exclude) %>%\n              count(word, sort = TRUE) \n\nword_count %>% head(15)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15 × 2\n   word        n\n   <chr>   <int>\n 1 life      746\n 2 family    497\n 3 world     453\n 4 love      447\n 5 woman     402\n 6 friends   383\n 7 school    290\n 8 home      263\n 9 lives     251\n10 takes     233\n11 father    228\n12 girl      209\n13 special   190\n14 save      189\n15 town      187\n```\n:::\n:::\n\n\n\n### Keep some words\n\nSimilarly, a word that is included in the stop word list may be informative for a particular data set. When this is the case, we want to keep the word by removing it from the exclusion list. For example, we may want to know the number of show descriptions that reference `one`, `two` or `three` characters or objects.\n\nHere's how we can keep the words \"one\", \"two\" and \"three\".\n\n\n::: {.cell source-line-numbers='3-5'}\n\n```{.r .cell-code}\nexclude <- stop_words$word\n\nkeep <- c(\"one\", \"two\", \"three\")\n\nexclude <- exclude[!exclude %in% keep]\n\nword_count <- tv_ratings %>%\n              unnest_tokens(word, description) %>%\n              filter(!word %in% exclude) %>%\n              count(word, sort = TRUE) \n\nword_count %>% head(15)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15 × 2\n   word            n\n   <chr>       <int>\n 1 life          746\n 2 family        497\n 3 world         453\n 4 love          447\n 5 two           443\n 6 woman         402\n 7 friends       383\n 8 series        358\n 9 one           330\n10 documentary   326\n11 school        290\n12 home          263\n13 three         263\n14 lives         251\n15 takes         233\n```\n:::\n:::\n\n\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}